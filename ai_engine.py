import os
import json
import random # For persona diversity
from openai import OpenAI
import vertexai
from vertexai.vision_models import ImageGenerationModel
from google import genai
from google.oauth2 import service_account
from google.auth.exceptions import DefaultCredentialsError
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
from datetime import datetime
import instructor
import httpx # For disabling HTTP/2 to prevent hangs


# Load .env
# Load .env (from cred/ directory)
load_dotenv("cred/.env")

# PROVIDER CONFIG
PROVIDER = os.getenv("LLM_PROVIDER", "openai").lower()
TEST_MODE = os.getenv("TEST_MODE", "false").lower() == "true"

ALLOWED_PROVIDERS = ["vertexai", "openai"]

# Model Configuration (Prod vs Test)
MODEL_MAP = {
    "vertexai": {"prod": "gemini-2.5-pro", "test": "gemini-2.5-flash"},
    "openai":   {"prod": "gpt-4o",         "test": "gpt-4o-mini"}
}

# ... (lines 28-30 skipped/implied by patch location, actuall I need to do this carefully)


# Select Model
mode_key = "test" if TEST_MODE else "prod"
MODEL_NAME = MODEL_MAP.get(PROVIDER, {}).get(mode_key, "gemini-2.5-pro")

if TEST_MODE:
    print(f"   ‚ö° TEST MODE ACTIVE: Using lightweight model ({MODEL_NAME}) & Minimal Data.")

# Diversity Settings
CHARACTER_UNIVERSES = [
    "Seinfeld", "The Office", "Parks and Rec", "Star Wars", "Marvel", 
    "Harry Potter", "Friends", "Lord of the Rings", "Breaking Bad", 
    "Game of Thrones", "Succession", "The Sopranos", "Grey's Anatomy", 
    "House MD", "Scrubs", "2 Broke Girls", "The Big Bang Theory", 
    "Brooklyn 99", "Superstore"
]

if PROVIDER not in ALLOWED_PROVIDERS:
    raise ValueError(f"‚ùå Invalid LLM_PROVIDER in .env: '{PROVIDER}'. Must be one of {ALLOWED_PROVIDERS}")

print(f"   ü§ñ AI Provider: {PROVIDER.upper()}")

# CLIENT INITIALIZATION
client = None

if PROVIDER == "openai":
    if "OPENAI_API_KEY" not in os.environ:
         raise ValueError("Missing OPENAI_API_KEY in .env")
    client = instructor.from_openai(
        OpenAI(
            api_key=os.environ.get("OPENAI_API_KEY"),
            http_client=httpx.Client(http2=False) # Fix for hangs
        )
    )


elif PROVIDER == "vertexai":
    project_id = os.getenv("GCP_PROJECT_ID", "").strip()
    location = os.getenv("GCP_LOCATION", "").strip()
    key_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "").strip()
    
    if not project_id or not location:
         raise ValueError("Missing GCP_PROJECT_ID or GCP_LOCATION in .env for Vertex AI")

    print(f"   üîë Validating Credentials: {key_path}")
    if not key_path or not os.path.exists(key_path):
        raise ValueError(f"‚ùå GOOGLE_APPLICATION_CREDENTIALS not found at: {key_path}")

    # Validate JSON integrity & Permissions
    try:
        creds = service_account.Credentials.from_service_account_file(
            key_path, 
            scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )
        print(f"   ‚úÖ Service Account Loaded: {creds.service_account_email}")
    except Exception as e:
        raise ValueError(f"‚ùå Invalid Service Account Key File: {e}")

    # Auto-correct Zone to Region
    if len(location.split('-')) > 2:
        old_loc = location
        location = '-'.join(location.split('-')[:2])
        print(f"   ‚ö†Ô∏è Adjusted GCP_LOCATION from '{old_loc}' to Region '{location}'")

    try:
        # 1. Init Vertex SDK
        # Force REST transport to avoid gRPC deadlocks on macOS
        vertexai.init(
            project=project_id, 
            location=location, 
            credentials=creds,
            api_transport="rest"
        )
        
        # 2. Init Instructor with Vertex AI Model
        # Using the specific model instance prevents client/version conflicts
        model = vertexai.generative_models.GenerativeModel(MODEL_NAME)
        client = instructor.from_vertexai(
            client=model,
            mode=instructor.Mode.VERTEXAI_TOOLS,
        )

    except Exception as e:
        raise RuntimeError(f"‚ùå Failed to initialize Vertex AI Client: {e}")

def check_connection() -> bool:
    """Pre-flight check to verify LLM reachability."""
    try:
        print(f"   üì° Testing AI Connection... (Model: {MODEL_NAME})", end="", flush=True)
        if PROVIDER == "vertexai":
            # Direct SDK call to avoid Instructor retries on Auth fail
            from vertexai.generative_models import GenerativeModel
            model = GenerativeModel(MODEL_NAME)
            resp = model.generate_content("Hello")
            if resp:
                print(" OK! ‚úÖ")
                return True

        elif PROVIDER == "openai":
             # Simple client check
             print(" OK! (OpenAI) ‚úÖ")
             return True
             
        return False
    except Exception as e:
        print(f" FAILED! ‚ùå\n   ‚ö†Ô∏è  Connection Error: {e}")
        return False

class PatientContactPeriod(BaseModel):
    """Period during which contact is valid."""
    start: str = Field(..., description="Start date YYYY-MM-DD")
    end: str = Field(..., description="End date YYYY-MM-DD or 'ongoing'")

class PatientContact(BaseModel):
    """Emergency contact or guardian - ALL fields required."""
    relationship: str = Field(..., description="e.g. 'Next of Kin', 'Mother', 'Spouse', 'Emergency Contact'")
    name: str = Field(..., description="Full name of contact")
    telecom: str = Field(..., description="Phone number e.g. '555-123-4567'")
    address: str = Field(..., description="Full address of contact")
    gender: str = Field(..., description="'male', 'female', 'other'")
    organization: str = Field("N/A", description="Organization name if contact is institutional, else 'N/A'")
    period_start: str = Field(..., description="Date contact relationship started (YYYY-MM-DD)")
    period_end: str = Field("ongoing", description="Date contact relationship ended or 'ongoing'")

class PatientCommunication(BaseModel):
    """Patient communication preferences."""
    language: str = Field(..., description="Primary language e.g. 'English', 'Spanish'")
    preferred: bool = Field(True, description="Whether this is the preferred communication method")

class PatientProvider(BaseModel):
    """Care provider details - ALL fields required."""
    generalPractitioner: str = Field(..., description="Full name of primary care provider e.g. 'Dr. Jane Smith, MD'")
    managingOrganization: str = Field(..., description="Name of managing clinic/hospital e.g. 'Mercy General Hospital'")

class PatientLink(BaseModel):
    """Link to other patient records."""
    other_patient: str = Field("N/A", description="ID of linked patient or 'N/A'")
    link_type: str = Field("N/A", description="Type of link: 'replaces', 'replaced-by', 'refer', 'seealso', or 'N/A'")

class SubscriberDetails(BaseModel):
    """Insurance subscriber details - person who holds the policy."""
    subscriber_id: str = Field(default="Unknown", description="Subscriber/Member ID e.g. 'MEM-123456789'")
    subscriber_name: str = Field(default="Unknown", description="Full name of policy holder")
    subscriber_relationship: str = Field(default="Self", description="Relationship to patient: 'Self', 'Spouse', 'Child', 'Other'")
    subscriber_dob: str = Field(default="1980-01-01", description="Subscriber date of birth YYYY-MM-DD")
    subscriber_address: str = Field(default="Same as Patient", description="Subscriber address if different from patient")

class PayerDetails(BaseModel):
    """Insurance/Payer information - ALL fields required."""
    payer_id: str = Field(default="J1113", description="Payer identifier e.g. 'J1113', 'UHC-001'")
    payer_name: str = Field(default="UnitedHealthcare", description="Full payer name e.g. 'UnitedHealthcare', 'Blue Cross Blue Shield', 'Aetna'")
    plan_name: str = Field(default="Choice Plus", description="Plan name e.g. 'Gold PPO', 'Choice Plus', 'Medicare Advantage'")
    plan_type: str = Field(default="PPO", description="Plan type: 'PPO', 'HMO', 'EPO', 'POS', 'Medicare', 'Medicaid'")
    group_id: str = Field(default="GRP-99999", description="Group/Employer ID e.g. 'GRP-98765'")
    group_name: str = Field(default="Employer Group", description="Group/Employer name e.g. 'Stark Industries', 'City of Pawnee'")
    member_id: str = Field(default="MBR-999999", description="Member ID on insurance card e.g. 'MBR-123456789'")
    policy_number: str = Field(default="POL-99999", description="Policy number e.g. 'POL-2025-001234'")
    effective_date: str = Field(default="2024-01-01", description="Coverage start date YYYY-MM-DD")
    termination_date: str = Field("ongoing", description="Coverage end date or 'ongoing'")
    copay_amount: str = Field(default="$25", description="Copay amount e.g. '$25', '$50'")
    deductible_amount: str = Field(default="$500", description="Annual deductible e.g. '$500', '$1500'")
    
    # Subscriber (policy holder)
    subscriber: SubscriberDetails = Field(default_factory=SubscriberDetails, description="Policy holder details")

class PatientPersona(BaseModel):
    """Complete FHIR-compliant patient persona - ALL fields populated."""
    # Core Demographics
    first_name: str = Field(..., description="Patient first name")
    last_name: str = Field(..., description="Patient last name")
    gender: str = Field(..., description="'male', 'female', 'other'")
    dob: str = Field(..., description="Date of birth YYYY-MM-DD")
    address: str = Field(..., description="Full home address")
    telecom: str = Field(..., description="Main phone number e.g. '555-555-5555'")
    
    # Biometrics (New Requirements)
    race: str = Field(..., description="Patient race/ethnicity e.g. 'Caucasian', 'Asian', 'Hispanic'")
    height: str = Field(..., description="Patient height e.g. '5 ft 10 in', '178 cm'")
    weight: str = Field(..., description="Patient weight e.g. '160 lbs', '72 kg'")
    
    # Extended Demographics
    maritalStatus: str = Field(..., description="'Married', 'Single', 'Divorced', 'Widowed', 'Separated'")
    multipleBirthBoolean: bool = Field(False, description="True if part of multiple birth")
    multipleBirthInteger: int = Field(1, description="Birth order if multiple birth, else 1")
    photo: str = Field("placeholder_patient_photo.png", description="Patient photo filename or URL")
    
    # Communication
    communication: PatientCommunication = Field(..., description="Communication preferences")
    
    # Nested Objects - ALL REQUIRED
    contact: PatientContact = Field(..., description="Emergency contact - MUST populate ALL fields: Name, Gender, Address, Telecom, etc.")
    provider: PatientProvider = Field(..., description="Care provider - MUST populate all fields")
    link: PatientLink = Field(default_factory=lambda: PatientLink(), description="Link to other patient records")
    
    # Insurance/Payer - MANDATORY
    payer: PayerDetails = Field(..., description="Insurance/Payer details - MUST populate ALL fields including subscriber")
    
    # Narrative
    bio_narrative: Optional[str] = Field(default="", description="Comprehensive biography/history (HPI, Social, Family). Use plain text, avoid markdown.")

from doc_validator import format_clinical_document

class StructuredClinicalDoc(BaseModel):
    """
    Layer 1: Raw Structured Content (AI Generation).
    The AI fills these fields. Python Helper formats them.
    """
    doc_id: str = Field(..., description="ID matching the SQL insert (e.g. 'DOC-101').")
    doc_type: str = Field(..., description="Type: 'CONSULT', 'IMAGING', 'LAB', 'DISCHARGE', 'ER_VISIT'.")
    title: str = Field(..., description="Descriptive title e.g. 'Cardiology_Consult'.")
    service_date: str = Field(..., description="YYYY-MM-DD")
    facility: str = Field(..., description="Facility Name")
    provider: str = Field(..., description="Provider Name")
    
    # Clinical Sections (Optional - AI fills relevant ones)
    chief_complaint: Optional[str] = None
    hpi: Optional[str] = None
    past_medical_history: Optional[List[str]] = None
    medications: Optional[List[str]] = None
    allergies: Optional[List[str]] = None
    social_history: Optional[str] = None
    family_history: Optional[str] = None
    review_of_systems: Optional[str] = None
    vitals: Optional[List[str]] = None
    physical_exam: Optional[str] = None
    labs: Optional[List[str]] = None
    imaging: Optional[str] = None
    assessment: Optional[str] = None
    plan: Optional[str] = None
    
    # Imaging Specific
    exam_type: Optional[str] = None
    indication: Optional[str] = None
    technique: Optional[str] = None
    findings: Optional[str] = None
    impression: Optional[str] = None
    
    # Narratives
    narrative: Optional[str] = None # For anything else

class GeneratedDocument(BaseModel):
    """
    Final Output Object (Layer 3).
    Contains the raw content string formatted by Python.
    """
    doc_id: str = Field(..., description="Document ID e.g. 'DOC-101'")
    title_hint: str = Field(..., description="Short descriptive title e.g. 'Cardiology_Consult', 'MRI_Knee'")
    content: str = Field(..., description="The full formatted text content of the document.")


class ModifiedSQLRaw(BaseModel):
    """Internal model for AI generation (Structured Data)."""
    updated_sql: str = Field(..., description="The fully rewritten, valid SQL code.")
    changes_summary: str = Field(..., description="A short bulleted list of the changes made to the SQL.")
    structured_documents: List[StructuredClinicalDoc] = Field(..., description="List of structured clinical documents.")
    patient_persona: PatientPersona = Field(..., description="The detailed, structured patient identity.")

class ClinicalDataPayload(BaseModel):
    """Public model for consumption (Pure Clinical Data)."""
    # No SQL fields
    changes_summary: str = Field(..., description="A short summary of the clinical scenario generated.")
    documents: List[GeneratedDocument]
    patient_persona: PatientPersona


def generate_clinical_data(case_details: dict, user_feedback: str = "", history_context: str = "", existing_persona: dict = None, excluded_names: List[str] = None, existing_filenames: List[str] = None) -> 'FinalResult':

    """
    Calls AI to generate clinical data (Persona + Documents) based on the case + feedback + history.
    Values referencing 'existing_persona' are STRICT constraints.
    """
    
    # Construct User Feedback Block
    feedback_instruction = ""
    if user_feedback:
        feedback_instruction = f"""
        **USER FEEDBACK / QA CORRECTIONS:**
        The user has provided specific instructions for this run. You MUST incorporate them while strictly adhering to the clinical outcome:
        > "{user_feedback}"
        """

    # Existing Documents Logic (Smart Append)
    existing_docs_instruction = ""
    if existing_filenames and len(existing_filenames) > 0:
        titles_str = ", ".join([f"'{f}'" for f in existing_filenames])
        existing_docs_instruction = f"""
        **EXISTING DOCUMENTS (INCREMENTAL MODE):**
        The following documents ALREADY EXIST for this patient:
        [{titles_str}]
        
        **CRITICAL INSTRUCTION:**
        - Do NOT regenerate the exact same document types/titles if they are already sufficient.
        - ONLY generate NEW documents if the clinical picture is incomplete (e.g., missing critical labs, imaging, or specialist consults).
        - If the existing documents fully cover the {case_details['outcome']} scenario, return an EMPTY list for 'documents'.
        - If generating new docs, ensure TITLES are unique and do not conflict with the list above.
        """
    else:
        # Default behavior: Force generation if no docs exist
        existing_docs_instruction = "4. **Data Density (MANDATORY)**:\n       - **Documents**: Minimum 5 distinct clinical documents (e.g., Consult, Lab_Report, Imaging_Report, Discharge_Summary, Specialist_Note)."

    # Identity Constraints
    if existing_persona:
        identity_constraint = f"""
        **STRICT IDENTITY LOCK (EXISTING PATIENT):**
        You MUST use the following demographics. DO NOT CHANGE THEM.
        - Name: {existing_persona.get('first_name')} {existing_persona.get('last_name')}
        - DOB: {existing_persona.get('dob')}
        - Gender: {existing_persona.get('gender')}
        - Address: {existing_persona.get('address')}
        - Telecom: {existing_persona.get('telecom')}
        - Provider: {(existing_persona.get('provider') or {}).get('generalPractitioner')} ({(existing_persona.get('provider') or {}).get('managingOrganization')})
        - Bio Narrative Strategy: Keep the *style* of the existing bio but update the clinical narrative to match the CURRENT procedure ({case_details['procedure']}).
        """

    else:
        # DYNAMIC DIVERSITY LOGIC
        # 1. Select Random Universe
        selected_universe = random.choice(CHARACTER_UNIVERSES)
        
        # 2. Build Exclusion String
        exclusion_instruction = ""
        if excluded_names:
            used_list = ", ".join(excluded_names[:50]) # Limit to 50 to avoid token bloat
            exclusion_instruction = f"**USED NAMES (AVOID THESE):** {used_list}."

        identity_constraint = f"""
        **IDENTITY GENERATION (STRICT DIVERSITY RULES):**
        - **Character Source**: Select a UNIQUE fictional character from the universe of **{selected_universe}** (TV/Movie/Book).
        - **VARIETY MANDATE**: {exclusion_instruction} Select a character NOT in the used list.
        - **Gender Balance**: You MUST randomize gender (Aim for 50% Male / 50% Female across runs).
        - **Demographics**: Generate accurate DOB, Address (matching the show's location), and Telecom.
        - **Provider**: REQUIRED. Generate a GP and Managing Org appropriate for the location.
        - **Bio Narrative**: Create a rich, multi-paragraph medical and social history consistent with the character's background but adapted to the patient scenario.
        
        **FEEDBACK OVERRIDE RULE:**
        IF the User Feedback (below) explicitly specifies a character name (e.g. "Use Spider-Man"), you MUST IGNORE the 'Universe' and 'Used Names' constraints and use the requested character.
        """

    prompt = f"""
    **CLINICAL SCENARIO Requirements (IMMUTABLE Source of Truth):**
    - Procedure: {case_details['procedure']}
    - Target Outcome: {case_details['outcome']}
    - Clinical Context: {case_details['details']}
    
    **PAST HISTORY (CONTEXT):**
    {history_context if history_context else "No prior history available."}

    {feedback_instruction}

    **INSTRUCTIONS:**
    1. **Identity & Consistency**:
       - Maintain strict patient identity if provided.
       - Ensure all documents match the patient demographics.
    2. **Clinical Logic Application**:
       - If Target is Denial/Low Probability -> REMOVE supporting evidence or make findings ambiguous/normal.
       - If Target is Approval -> ENSURE strong supporting evidence exists.
    3. **Clinical Status**:
       - The *Target Procedure* ({case_details['procedure']}) Status: 'requested'.
       - All *historical* procedures must be implied as 'completed'.
    {existing_docs_instruction}
    5. **Document Generation (CRITICAL Rules)**:
       - Generate `documents` list with rich content.
       - **PROHIBITED TITLES**: No "Approval Letters" or "Denial Notices". Only clinical evidence.
       - **TITLES**: MUST be UNIQUE and DESCRIPTIVE (e.g. "Cardiology_Consult", "Echo_Report").
       - **STRICT FORMATTING (VALIDATOR COMPLIANCE)**:
         - **MUST START WITH**: `--- REPORT START ---`
         - **MUST END WITH**: `--- REPORT END ---`
         - **MUST HAVE METADATA BLOCK**:
           ```text
           [REPORT_METADATA]
           PATIENT_ID: (Use Case ID)
           MRN: (Current MRN)
           PATIENT_NAME: (Full Name)
           DOB: (YYYY-MM-DD)
           REPORT_DATE: (YYYY-MM-DD from Timeline)
           ...
           ```
         - **NO MARKDOWN BOLD**: Do not use `**Text**`.
         - **NO TRIPLE QUOTES**: Do not use `'''`.
       - **METADATA**:
          - `service_date`: Must be logically consistent (Historical dates for evidence, recent for request).
          - `facility_name` & `provider_name`: Realistic and consistent.
    6. **TIMELINE LOGIC (CRITICAL)**:
       - **Target Procedure Date**: Future (e.g. 2-3 weeks from now).
       - **Historical Context**: All Consults, Labs, Imaging must be PAST dated.
       - Example: "Today is 2025-05-01. Requesting procedure for 2025-05-20. Evidence generated from 2025-04-15."
    7. **Persona Generation (COMPLETE FHIR-COMPLIANT DATA)**:
       - You MUST populate the `patient_persona` object with ALL fields. **NO NULL VALUES ALLOWED**.
       {identity_constraint}
       - **Required Fields (ALL MUST BE FILLED)**:
         - `first_name`, `last_name`, `gender`, `dob`, `address`, `telecom`
         - **Biometrics**: `race`, `height`, `weight`
         - `maritalStatus`, `photo` (default placeholder)
         - `communication`, `contact` (Emergency)
         - `provider` (GP), `link` (N/A)
         - `payer` (MANDATORY): Full Insurance details.
       - **Bio Narrative (PLAIN TEXT)**:
         - Rich multi-paragraph history (Personality, HPI, Social). NO Markdown.
    8. **Output**: Return the `ClinicalDataPayload` JSON.
    """

    # Use create_with_completion to get usage stats
    try:
        # Convert system prompt to user prompt for Vertex AI compatibility
        system_role = "user" if PROVIDER == "vertexai" else "system"

        # Standardize arguments
        # Standardize arguments
        kwargs = {
            "model": MODEL_NAME,
            "response_model": ClinicalDataPayload,
            "messages": [
                {"role": system_role, "content": """You are an expert healthcare data generator.
Your task: generate realistic, diverse clinical personas and medical documents based on clinical use cases.

=== Core Rules ===
1. Generate data that is FHIR-compliant and visually realistic.
2. **Inference**: If CPT/procedure is not provided, infer the most clinically appropriate code.
3. Suggest CPTs intelligently.
4. Output valid, JSON-structured data.
5. **No SQL**: Do not generate SQL. Focus on the Object Model.

=== CRITICAL PROJECT CONSTRAINTS ===
A. **Data Density**:
   - Documents: Minimum 5 distinct clinical documents.
B. **Clinical Status**:
   - Target Procedure must be 'requested'.
   - Historical Procedures 'completed'.
C. **NO AI RESIDUE**:
   - No "[Redacted]" or "Jane Doe". Use realistic names from Pop Culture Universes (e.g. Characters).
   - Authenticity: 100%.
D. **NAMING CONVENTION**:
   - Use names from: Friends, Marvel, Star Wars, etc. (as per constraints).
"""},
                {"role": "user", "content": prompt}
            ]
        }
        
        if PROVIDER == "vertexai":
             print(f"   [DEBUG] Calling Vertex AI Direct (Bypassing Instructor) - Model: {MODEL_NAME}")
             print("   [DEBUG] Sending request...")
             
             try:
                 # Flatten messages for simple prompt (or use chat)
                 # Vertex chat needs history... let's just use the final user prompt + system context
                 # Note: client is Instructor, client.client is GenerativeModel
                 model_instance = client.client 
                 
                 from vertexai.generative_models import GenerationConfig
                 
                 # Prepare Prompt
                 msgs = kwargs['messages']
                 # msgs is a list of dicts: [{'role':..., 'content':...}, ...]
                 full_prompt = f"{msgs[0]['content']}\n\nUser Input:\n{msgs[1]['content']}"
                 
                 resp = model_instance.generate_content(
                    full_prompt,
                    generation_config=GenerationConfig(
                        response_mime_type="application/json",
                        # response_schema=ModifiedSQL.model_json_schema() # Causing hangs
                    )
                 )
                 
                 print("   [DEBUG] Request complete.")
                 print(f"   [DEBUG] Raw Response Length: {len(resp.text)}")
                 
                 # Handle potential List response (e.g. [Object]) vs Object
                 import json
                 try:
                     raw_text = resp.text.strip()
                     # Basic cleanup if md block
                     if raw_text.startswith("```json"):
                         raw_text = raw_text[7:]
                     if raw_text.endswith("```"):
                         raw_text = raw_text[:-3]
                     
                     data = json.loads(raw_text)
                     if isinstance(data, list) and len(data) > 0:
                         print("   ‚ö†Ô∏è  AI returned a LIST. extracted first item.")
                         data = data[0]
                     
                     response_obj = ClinicalDataPayload.model_validate(data)
                 except Exception as e:
                     print(f"   ‚ö†Ô∏è  Manual JSON Parsing Failed: {e}. Retrying with strict validate...")
                     response_obj = ClinicalDataPayload.model_validate_json(resp.text)
                 
                 # Fake clean usage for now or extract
                 usage_stats = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
                 if resp.usage_metadata:
                     usage_stats["prompt_tokens"] = resp.usage_metadata.prompt_token_count
                     usage_stats["completion_tokens"] = resp.usage_metadata.candidates_token_count
                     usage_stats["total_tokens"] = resp.usage_metadata.total_token_count
                     
                 return response_obj, usage_stats
                 
             except Exception as e:
                 print(f"   ‚ùå Vertex Direct Call Failed: {e}")
                 # Fallback or raise
                 raise e

        # ORIGINAL PATH FOR OPENAI
        print(f"   [DEBUG] Calling AI Provider: {PROVIDER}, Model: {MODEL_NAME}")
        print("   [DEBUG] Sending request...")
        completion_resp = client.chat.completions.create_with_completion(**kwargs)
        print("   [DEBUG] Request complete.")
        
        # Handle Instructor Tuple Return (Response, Completion)
        response_obj = None
        completion = None
        
        if isinstance(completion_resp, tuple):
             response_obj = completion_resp[0]
             completion = completion_resp[1]
        else:
             # Fallback
             response_obj = completion_resp
             
        if response_obj is None:
            print("   ‚ùå CRITICAL: AI returned NO response object (None).")
            return None

        usage_stats = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
        if completion and hasattr(completion, 'usage') and completion.usage:
             usage_stats["prompt_tokens"] = completion.usage.prompt_tokens
             usage_stats["completion_tokens"] = completion.usage.completion_tokens
             usage_stats["total_tokens"] = completion.usage.total_tokens

        return response_obj, usage_stats
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è AI Generation Failed: {e}")
        # Return dummy to prevent crash if possible, or re-raise
        raise e




def generate_clinical_image(context: str, image_type: str, output_path: str = None) -> str:
    # Generates a synthetic medical image based on the clinical context.
    # Construct a safe, clinical prompt
    prompt = f"A direct, close-up medical {image_type} scan result. Clinical Context: {context}. Style: AUTHENTIC DICOM/RADIOGRAPH. Black and white ONLY. High contrast. CRITICAL RESTRICTIONS: NO HUMANS, NO FACES, NO BODY PARTS visible (except internal anatomy). NO DOCTORS, NO MEDICAL DEVICES/MACHINES surrounding it. NO TEXT, NO LABELS, NO WATERMARKS. Just the raw scan image on a black background."
    
    try:
        if PROVIDER == "vertexai":
            if not output_path:
                 print("   ‚ö†Ô∏è Vertex Image Gen requires 'output_path'")
                 return None
                 
            # VERTEX AI / IMAGEN (Preview)
            # Ensure Project/Location init is done (it is in global init)
            
            # "imagen-3.0-generate-001" is the common identifier for Imagen 3 on Vertex
            # Updated to 002 based on availability
            model = ImageGenerationModel.from_pretrained("imagen-3.0-generate-002")
            
            response = model.generate_images(
                prompt=prompt[:3900],
                number_of_images=1,
                aspect_ratio="1:1",
            )
            
            # Save to disk
            if response.images:
                response.images[0].save(output_path)
                return output_path
            else:
                return None

        else:
            # OPENAI (DALL-E 3)
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt[:3900], 
                size="1024x1024", 
                quality="standard",
                n=1,
            )
            return response.data[0].url

    except Exception as e:
        print(f"   ‚ö†Ô∏è Image Generation Failed: {e}")
        return None

def fix_document_content(content: str, errors: List[str]) -> str:
    try:
        system_role = "user" if PROVIDER == "vertexai" else "system"
        
        # Use single quotes for inner f-string keys to avoid conflict
        prompt = f"Fix the following Clinical Document content to resolve these specific validation errors:\\nERRORS: {errors}\\n\\nCONTENT:\\n{content}\\n\\nRETURN ONLY THE FIXED CONTENT string. No markdown code blocks."
        
        # Use lightweight model for fixes if possible, or just same model
        # For now reusing the main configured client
        kwargs = {
            "model": MODEL_NAME, # Could use lighter model
            "messages": [
                {"role": system_role, "content": "You are a document repair bot. Output only the fixed text."},
                {"role": "user", "content": prompt}
            ]
        }
        
        if PROVIDER == "openai":
            response = client.chat.completions.create(**kwargs)
            return response.choices[0].message.content
        elif PROVIDER == "vertexai":
            # Simplified for vertex
            chat = client.get_model(MODEL_NAME).start_chat()
            resp = chat.send_message(prompt)
            return resp.text
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è Repair Failed: {e}")
        return content # Return original if fix fails
